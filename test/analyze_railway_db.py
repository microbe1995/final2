#!/usr/bin/env python3
"""
Railway DB ì§ì ‘ ì—°ê²° ìŠ¤í‚¤ë§ˆ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
rule1.mdc ê·œì¹™ì— ë”°ë¼ Railway PostgreSQL DBë¥¼ ë¨¼ì € í™•ì¸í•©ë‹ˆë‹¤.
"""

import asyncio
import asyncpg
import json
from datetime import datetime
from typing import Dict, List, Any

# Railway DB ì—°ê²° ì •ë³´ (rule1.mdcì—ì„œ ê°€ì ¸ì˜´)
RAILWAY_DATABASE_URL = "postgresql://postgres:eQGfytQNhXYAZxsJYlFhYagpJAgstrni@shortline.proxy.rlwy.net:46071/railway"

async def analyze_railway_database():
    """Railway DB ìŠ¤í‚¤ë§ˆë¥¼ ì§ì ‘ ë¶„ì„í•©ë‹ˆë‹¤."""
    
    try:
        # Railway DB ì§ì ‘ ì—°ê²°
        print("ğŸ”— Railway DBì— ì§ì ‘ ì—°ê²° ì¤‘...")
        print(f"ğŸ“ ì—°ê²° ì£¼ì†Œ: {RAILWAY_DATABASE_URL.split('@')[1] if '@' in RAILWAY_DATABASE_URL else '***'}")
        
        conn = await asyncpg.connect(RAILWAY_DATABASE_URL)
        print("âœ… Railway DB ì—°ê²° ì„±ê³µ!")
        
        # 1. ëª¨ë“  í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ
        print("\nğŸ“‹ 1. Railway DB í…Œì´ë¸” ëª©ë¡")
        print("=" * 60)
        
        tables_query = """
        SELECT table_name, table_type
        FROM information_schema.tables 
        WHERE table_schema = 'public'
        ORDER BY table_name;
        """
        
        tables = await conn.fetch(tables_query)
        
        table_info = {}
        for table in tables:
            table_name = table['table_name']
            table_type = table['table_type']
            print(f"ğŸ“Š {table_name} ({table_type})")
            table_info[table_name] = {'type': table_type, 'columns': []}
        
        print(f"\nğŸ“Š ì´ í…Œì´ë¸” ìˆ˜: {len([t for t in table_info.values() if t['type'] == 'BASE TABLE'])}")
        
        # 2. ê° í…Œì´ë¸”ì˜ ìƒì„¸ êµ¬ì¡° ë¶„ì„
        print("\nğŸ” 2. í…Œì´ë¸”ë³„ ìƒì„¸ êµ¬ì¡° ë¶„ì„")
        print("=" * 60)
        
        for table_name in table_info.keys():
            if table_info[table_name]['type'] == 'BASE TABLE':
                print(f"\nğŸ“‹ í…Œì´ë¸”: {table_name}")
                print("-" * 40)
                
                # ì»¬ëŸ¼ ì •ë³´ ì¡°íšŒ
                columns_query = """
                SELECT 
                    column_name,
                    data_type,
                    is_nullable,
                    column_default,
                    character_maximum_length,
                    numeric_precision,
                    numeric_scale
                FROM information_schema.columns 
                WHERE table_name = $1
                ORDER BY ordinal_position;
                """
                
                columns = await conn.fetch(columns_query, table_name)
                
                for col in columns:
                    col_info = {
                        'name': col['column_name'],
                        'type': col['data_type'],
                        'nullable': col['is_nullable'],
                        'default': col['column_default'],
                        'max_length': col['character_maximum_length'],
                        'precision': col['numeric_precision'],
                        'scale': col['numeric_scale']
                    }
                    
                    table_info[table_name]['columns'].append(col_info)
                    
                    # ì»¬ëŸ¼ ì •ë³´ ì¶œë ¥ (ì•ˆì „í•œ ë°©ì‹ìœ¼ë¡œ)
                    nullable_str = "NULL" if col['is_nullable'] == 'YES' else "NOT NULL"
                    default_str = f" DEFAULT {col['column_default']}" if col['column_default'] else ""
                    
                    if col['data_type'] == 'character varying':
                        max_len = col.get('character_maximum_length', '?')
                        type_str = f"VARCHAR({max_len})" if max_len != '?' else "VARCHAR"
                    elif col['data_type'] == 'numeric':
                        precision = col.get('numeric_precision', '?')
                        scale = col.get('numeric_scale', '?')
                        if precision != '?' and scale != '?':
                            type_str = f"NUMERIC({precision},{scale})"
                        else:
                            type_str = "NUMERIC"
                    else:
                        type_str = col['data_type']
                    
                    print(f"  {col['column_name']:<25} {type_str:<20} {nullable_str}{default_str}")
        
        # 3. ì¸ë±ìŠ¤ ì •ë³´ ë¶„ì„
        print("\nğŸ” 3. í…Œì´ë¸”ë³„ ì¸ë±ìŠ¤ ë¶„ì„")
        print("=" * 60)
        
        for table_name in table_info.keys():
            if table_info[table_name]['type'] == 'BASE TABLE':
                print(f"\nğŸ“‹ í…Œì´ë¸”: {table_name}")
                print("-" * 40)
                
                indexes_query = """
                SELECT 
                    indexname,
                    indexdef
                FROM pg_indexes 
                WHERE tablename = $1;
                """
                
                indexes = await conn.fetch(indexes_query, table_name)
                
                if indexes:
                    for idx in indexes:
                        print(f"  ğŸ”— {idx['indexname']}")
                        print(f"     {idx['indexdef']}")
                else:
                    print("  âš ï¸ ì¸ë±ìŠ¤ ì—†ìŒ")
        
        # 4. ì™¸ë˜í‚¤ ê´€ê³„ ë¶„ì„
        print("\nğŸ” 4. ì™¸ë˜í‚¤ ê´€ê³„ ë¶„ì„")
        print("=" * 60)
        
        for table_name in table_info.keys():
            if table_info[table_name]['type'] == 'BASE TABLE':
                print(f"\nğŸ“‹ í…Œì´ë¸”: {table_name}")
                print("-" * 40)
                
                foreign_keys_query = """
                SELECT 
                    tc.constraint_name,
                    tc.table_name,
                    kcu.column_name,
                    ccu.table_name AS foreign_table_name,
                    ccu.column_name AS foreign_column_name
                FROM information_schema.table_constraints AS tc
                JOIN information_schema.key_column_usage AS kcu
                    ON tc.constraint_name = kcu.constraint_name
                JOIN information_schema.constraint_column_usage AS ccu
                    ON ccu.constraint_name = tc.constraint_name
                WHERE tc.constraint_type = 'FOREIGN KEY' 
                    AND tc.table_name = $1;
                """
                
                foreign_keys = await conn.fetch(foreign_keys_query, table_name)
                
                if foreign_keys:
                    for fk in foreign_keys:
                        print(f"  ğŸ”— {fk['column_name']} â†’ {fk['foreign_table_name']}.{fk['foreign_column_name']}")
                else:
                    print("  âš ï¸ ì™¸ë˜í‚¤ ì—†ìŒ")
        
        # 5. ë°°ì¶œëŸ‰ ê´€ë ¨ í…Œì´ë¸” ìƒì„¸ ë¶„ì„
        print("\nğŸ” 5. ë°°ì¶œëŸ‰ ê´€ë ¨ í…Œì´ë¸” ìƒì„¸ ë¶„ì„")
        print("=" * 60)
        
        emission_tables = ['process_attrdir_emission', 'matdir', 'fueldir', 'edge', 'process', 'product']
        
        for table_name in emission_tables:
            if table_name in table_info:
                print(f"\nğŸ“‹ í…Œì´ë¸”: {table_name}")
                print("-" * 40)
                
                # í…Œì´ë¸” ë°ì´í„° ê°œìˆ˜ í™•ì¸
                try:
                    count_query = f"SELECT COUNT(*) as count FROM {table_name};"
                    count_result = await conn.fetchrow(count_query)
                    row_count = count_result['count'] if count_result else 0
                    print(f"  ğŸ“Š ì´ ë ˆì½”ë“œ ìˆ˜: {row_count}")
                    
                    # ìƒ˜í”Œ ë°ì´í„° í™•ì¸
                    if row_count > 0:
                        sample_query = f"SELECT * FROM {table_name} LIMIT 2;"
                        sample_data = await conn.fetch(sample_query)
                        
                        for i, row in enumerate(sample_data, 1):
                            print(f"  ğŸ“ ìƒ˜í”Œ {i}: {dict(row)}")
                    else:
                        print("  âš ï¸ ë°ì´í„° ì—†ìŒ")
                        
                except Exception as e:
                    print(f"  âŒ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        # 6. CBAM ë°°ì¶œëŸ‰ ëˆ„ì  ì „ë‹¬ì„ ìœ„í•œ í˜„ì¬ ìƒí™© ë¶„ì„
        print("\nğŸ¯ 6. CBAM ë°°ì¶œëŸ‰ ëˆ„ì  ì „ë‹¬ í˜„í™© ë¶„ì„")
        print("=" * 60)
        
        print("\nğŸ“Š í•µì‹¬ í…Œì´ë¸” í˜„í™©:")
        
        # process_attrdir_emission í…Œì´ë¸” í™•ì¸
        if 'process_attrdir_emission' in table_info:
            print("  âœ… process_attrdir_emission í…Œì´ë¸” ì¡´ì¬")
            
            # ëˆ„ì  ë°°ì¶œëŸ‰ í•„ë“œ í™•ì¸
            has_cumulative = any(col['name'] == 'cumulative_emission' 
                               for col in table_info['process_attrdir_emission']['columns'])
            
            if has_cumulative:
                print("  âœ… cumulative_emission í•„ë“œ ì´ë¯¸ ì¡´ì¬")
            else:
                print("  âŒ cumulative_emission í•„ë“œ ì—†ìŒ - ì¶”ê°€ í•„ìš”")
                
            # ê¸°ì¡´ í•„ë“œë“¤ í™•ì¸
            existing_fields = [col['name'] for col in table_info['process_attrdir_emission']['columns']]
            print(f"  ğŸ“‹ ê¸°ì¡´ í•„ë“œë“¤: {', '.join(existing_fields)}")
        else:
            print("  âŒ process_attrdir_emission í…Œì´ë¸” ì—†ìŒ - ìƒì„± í•„ìš”")
        
        # edge í…Œì´ë¸” í™•ì¸
        if 'edge' in table_info:
            print("  âœ… edge í…Œì´ë¸” ì¡´ì¬")
            
            # edge_kind í•„ë“œ í™•ì¸
            has_edge_kind = any(col['name'] == 'edge_kind' 
                               for col in table_info['edge']['columns'])
            
            if has_edge_kind:
                print("  âœ… edge_kind í•„ë“œ ì¡´ì¬ (continue/produce/consume)")
                
                # edge_kind ê°’ë“¤ í™•ì¸
                try:
                    edge_kinds_query = "SELECT DISTINCT edge_kind FROM edge;"
                    edge_kinds = await conn.fetch(edge_kinds_query)
                    kinds = [row['edge_kind'] for row in edge_kinds]
                    print(f"  ğŸ“‹ í˜„ì¬ edge_kind ê°’ë“¤: {', '.join(kinds) if kinds else 'ì—†ìŒ'}")
                except Exception as e:
                    print(f"  âš ï¸ edge_kind ê°’ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            else:
                print("  âŒ edge_kind í•„ë“œ ì—†ìŒ - ì¶”ê°€ í•„ìš”")
        else:
            print("  âŒ edge í…Œì´ë¸” ì—†ìŒ - ìƒì„± í•„ìš”")
        
        # 7. ìŠ¤í‚¤ë§ˆ í™•ì¥ ê¶Œì¥ì‚¬í•­
        print("\nğŸ”§ 7. ìŠ¤í‚¤ë§ˆ í™•ì¥ ê¶Œì¥ì‚¬í•­")
        print("=" * 60)
        
        recommendations = []
        
        if 'process_attrdir_emission' in table_info:
            if not any(col['name'] == 'cumulative_emission' for col in table_info['process_attrdir_emission']['columns']):
                recommendations.append("process_attrdir_emission í…Œì´ë¸”ì— cumulative_emission í•„ë“œ ì¶”ê°€")
        
        if 'edge' not in table_info:
            recommendations.append("edge í…Œì´ë¸” ìƒì„± (ê³µì • ê°„ ì—°ê²° ê´€ë¦¬)")
        
        if recommendations:
            print("  ğŸ“‹ ê¶Œì¥ ìŠ¤í‚¤ë§ˆ í™•ì¥:")
            for i, rec in enumerate(recommendations, 1):
                print(f"    {i}. {rec}")
        else:
            print("  âœ… ëª¨ë“  í•„ìš”í•œ í…Œì´ë¸”ê³¼ í•„ë“œê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
        
        # 8. ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
        print("\nğŸ’¾ 8. ë¶„ì„ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥")
        print("=" * 60)
        
        analysis_result = {
            'analysis_date': datetime.now().isoformat(),
            'database_url': RAILWAY_DATABASE_URL.split('@')[1] if '@' in RAILWAY_DATABASE_URL else '***',
            'total_tables': len([t for t in table_info.values() if t['type'] == 'BASE TABLE']),
            'tables': table_info,
            'cbam_analysis': {
                'has_process_attrdir_emission': 'process_attrdir_emission' in table_info,
                'has_cumulative_emission': any(
                    col['name'] == 'cumulative_emission' 
                    for table in table_info.values() 
                    for col in table.get('columns', [])
                ),
                'has_edge_table': 'edge' in table_info,
                'has_edge_kind': any(
                    col['name'] == 'edge_kind' 
                    for col in table_info.get('edge', {}).get('columns', [])
                )
            },
            'recommendations': recommendations
        }
        
        with open('railway_db_analysis.json', 'w', encoding='utf-8') as f:
            json.dump(analysis_result, f, indent=2, ensure_ascii=False, default=str)
        
        print("âœ… ë¶„ì„ ê²°ê³¼ê°€ railway_db_analysis.json íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        await conn.close()
        print("\nğŸ”— Railway DB ì—°ê²° ì¢…ë£Œ")
        
        return analysis_result
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    print("ğŸš€ Railway DB ì§ì ‘ ì—°ê²° ìŠ¤í‚¤ë§ˆ ë¶„ì„ ì‹œì‘")
    print("=" * 60)
    print("ğŸ“ rule1.mdc ê·œì¹™ì— ë”°ë¼ Railway PostgreSQL DBë¥¼ ë¨¼ì € í™•ì¸í•©ë‹ˆë‹¤.")
    print("=" * 60)
    
    result = asyncio.run(analyze_railway_database())
    
    if result:
        print("\nğŸ¯ ë¶„ì„ ì™„ë£Œ! ë‹¤ìŒ ë‹¨ê³„:")
        print("1. railway_db_analysis.json íŒŒì¼ í™•ì¸")
        print("2. í˜„ì¬ DB ìŠ¤í‚¤ë§ˆ í˜„í™© íŒŒì•…")
        print("3. í•„ìš”í•œ ìŠ¤í‚¤ë§ˆ í™•ì¥ ê³„íš ìˆ˜ë¦½")
        print("4. DB ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±")
    else:
        print("\nâŒ ë¶„ì„ ì‹¤íŒ¨! ì˜¤ë¥˜ë¥¼ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
