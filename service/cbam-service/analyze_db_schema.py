#!/usr/bin/env python3
"""
Railway DB ìŠ¤í‚¤ë§ˆ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
í˜„ì¬ í…Œì´ë¸” êµ¬ì¡°ë¥¼ íŒŒì•…í•˜ì—¬ ë°°ì¶œëŸ‰ ëˆ„ì  ì „ë‹¬ì„ ìœ„í•œ ìŠ¤í‚¤ë§ˆ í™•ì¥ ê³„íšì„ ìˆ˜ë¦½í•©ë‹ˆë‹¤.
"""

import os
import asyncio
import asyncpg
from typing import Dict, List, Any
import json
from datetime import datetime

# í™˜ê²½ë³€ìˆ˜ì—ì„œ DB ì—°ê²° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
DATABASE_URL = os.getenv("DATABASE_URL")

async def analyze_database_schema():
    """ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
    
    if not DATABASE_URL:
        print("âŒ DATABASE_URL í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    try:
        # DB ì—°ê²°
        print("ğŸ”— Railway DBì— ì—°ê²° ì¤‘...")
        conn = await asyncpg.connect(DATABASE_URL)
        print("âœ… DB ì—°ê²° ì„±ê³µ!")
        
        # 1. ëª¨ë“  í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ
        print("\nğŸ“‹ 1. ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ëª©ë¡")
        print("=" * 50)
        
        tables_query = """
        SELECT table_name, table_type
        FROM information_schema.tables 
        WHERE table_schema = 'public'
        ORDER BY table_name;
        """
        
        tables = await conn.fetch(tables_query)
        
        table_info = {}
        for table in tables:
            table_name = table['table_name']
            table_type = table['table_type']
            print(f"ğŸ“Š {table_name} ({table_type})")
            table_info[table_name] = {'type': table_type, 'columns': []}
        
        # 2. ê° í…Œì´ë¸”ì˜ ìƒì„¸ êµ¬ì¡° ë¶„ì„
        print("\nğŸ” 2. í…Œì´ë¸”ë³„ ìƒì„¸ êµ¬ì¡° ë¶„ì„")
        print("=" * 50)
        
        for table_name in table_info.keys():
            if table_info[table_name]['type'] == 'BASE TABLE':
                print(f"\nğŸ“‹ í…Œì´ë¸”: {table_name}")
                print("-" * 30)
                
                # ì»¬ëŸ¼ ì •ë³´ ì¡°íšŒ
                columns_query = """
                SELECT 
                    column_name,
                    data_type,
                    is_nullable,
                    column_default,
                    character_maximum_length,
                    numeric_precision,
                    numeric_scale
                FROM information_schema.columns 
                WHERE table_name = $1
                ORDER BY ordinal_position;
                """
                
                columns = await conn.fetch(columns_query, table_name)
                
                for col in columns:
                    col_info = {
                        'name': col['column_name'],
                        'type': col['data_type'],
                        'nullable': col['is_nullable'],
                        'default': col['column_default'],
                        'max_length': col['character_maximum_length'],
                        'precision': col['numeric_precision'],
                        'scale': col['numeric_scale']
                    }
                    
                    table_info[table_name]['columns'].append(col_info)
                    
                    # ì»¬ëŸ¼ ì •ë³´ ì¶œë ¥
                    nullable_str = "NULL" if col['is_nullable'] == 'YES' else "NOT NULL"
                    default_str = f" DEFAULT {col['column_default']}" if col['column_default'] else ""
                    
                    if col['data_type'] == 'character varying':
                        type_str = f"VARCHAR({col['max_length']})"
                    elif col['data_type'] == 'numeric':
                        type_str = f"NUMERIC({col['precision']},{col['scale']})"
                    else:
                        type_str = col['data_type']
                    
                    print(f"  {col['column_name']:<20} {type_str:<15} {nullable_str}{default_str}")
        
        # 3. ì¸ë±ìŠ¤ ì •ë³´ ë¶„ì„
        print("\nğŸ” 3. í…Œì´ë¸”ë³„ ì¸ë±ìŠ¤ ë¶„ì„")
        print("=" * 50)
        
        for table_name in table_info.keys():
            if table_info[table_name]['type'] == 'BASE TABLE':
                print(f"\nğŸ“‹ í…Œì´ë¸”: {table_name}")
                print("-" * 30)
                
                indexes_query = """
                SELECT 
                    indexname,
                    indexdef
                FROM pg_indexes 
                WHERE tablename = $1;
                """
                
                indexes = await conn.fetch(indexes_query, table_name)
                
                if indexes:
                    for idx in indexes:
                        print(f"  ğŸ”— {idx['indexname']}")
                        print(f"     {idx['indexdef']}")
                else:
                    print("  âš ï¸ ì¸ë±ìŠ¤ ì—†ìŒ")
        
        # 4. ì™¸ë˜í‚¤ ê´€ê³„ ë¶„ì„
        print("\nğŸ” 4. ì™¸ë˜í‚¤ ê´€ê³„ ë¶„ì„")
        print("=" * 50)
        
        for table_name in table_info.keys():
            if table_info[table_name]['type'] == 'BASE TABLE':
                print(f"\nğŸ“‹ í…Œì´ë¸”: {table_name}")
                print("-" * 30)
                
                foreign_keys_query = """
                SELECT 
                    tc.constraint_name,
                    tc.table_name,
                    kcu.column_name,
                    ccu.table_name AS foreign_table_name,
                    ccu.column_name AS foreign_column_name
                FROM information_schema.table_constraints AS tc
                JOIN information_schema.key_column_usage AS kcu
                    ON tc.constraint_name = kcu.constraint_name
                JOIN information_schema.constraint_column_usage AS ccu
                    ON ccu.constraint_name = tc.constraint_name
                WHERE tc.constraint_type = 'FOREIGN KEY' 
                    AND tc.table_name = $1;
                """
                
                foreign_keys = await conn.fetch(foreign_keys_query, table_name)
                
                if foreign_keys:
                    for fk in foreign_keys:
                        print(f"  ğŸ”— {fk['column_name']} â†’ {fk['foreign_table_name']}.{fk['foreign_column_name']}")
                else:
                    print("  âš ï¸ ì™¸ë˜í‚¤ ì—†ìŒ")
        
        # 5. ìƒ˜í”Œ ë°ì´í„° í™•ì¸ (ë°°ì¶œëŸ‰ ê´€ë ¨ í…Œì´ë¸”)
        print("\nğŸ” 5. ë°°ì¶œëŸ‰ ê´€ë ¨ í…Œì´ë¸” ìƒ˜í”Œ ë°ì´í„°")
        print("=" * 50)
        
        emission_tables = ['process_attrdir_emission', 'matdir', 'fueldir']
        
        for table_name in emission_tables:
            if table_name in table_info:
                print(f"\nğŸ“‹ í…Œì´ë¸”: {table_name}")
                print("-" * 30)
                
                try:
                    sample_query = f"SELECT * FROM {table_name} LIMIT 3;"
                    sample_data = await conn.fetch(sample_query)
                    
                    if sample_data:
                        for i, row in enumerate(sample_data, 1):
                            print(f"  ğŸ“ ìƒ˜í”Œ {i}: {dict(row)}")
                    else:
                        print("  âš ï¸ ë°ì´í„° ì—†ìŒ")
                        
                except Exception as e:
                    print(f"  âŒ ìƒ˜í”Œ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        # 6. ìŠ¤í‚¤ë§ˆ í™•ì¥ ê³„íš ì œì•ˆ
        print("\nğŸ¯ 6. ë°°ì¶œëŸ‰ ëˆ„ì  ì „ë‹¬ì„ ìœ„í•œ ìŠ¤í‚¤ë§ˆ í™•ì¥ ê³„íš")
        print("=" * 50)
        
        print("\nğŸ“Š í˜„ì¬ ìƒí™©:")
        if 'process_attrdir_emission' in table_info:
            print("  âœ… process_attrdir_emission í…Œì´ë¸” ì¡´ì¬")
            print("  âœ… attrdir_em í•„ë“œ ì¡´ì¬ (ì§ì ‘ê·€ì†ë°°ì¶œëŸ‰)")
            
            # ëˆ„ì  ë°°ì¶œëŸ‰ í•„ë“œ í™•ì¸
            has_cumulative = any(col['name'] == 'cumulative_emission' 
                               for col in table_info['process_attrdir_emission']['columns'])
            
            if has_cumulative:
                print("  âœ… cumulative_emission í•„ë“œ ì´ë¯¸ ì¡´ì¬")
            else:
                print("  âŒ cumulative_emission í•„ë“œ ì—†ìŒ - ì¶”ê°€ í•„ìš”")
        else:
            print("  âŒ process_attrdir_emission í…Œì´ë¸” ì—†ìŒ - ìƒì„± í•„ìš”")
        
        if 'edge' in table_info:
            print("  âœ… edge í…Œì´ë¸” ì¡´ì¬")
            print("  âœ… edge_kind í•„ë“œ ì¡´ì¬ (continue/produce/consume)")
        else:
            print("  âŒ edge í…Œì´ë¸” ì—†ìŒ - ìƒì„± í•„ìš”")
        
        print("\nğŸ”§ ê¶Œì¥ ìŠ¤í‚¤ë§ˆ í™•ì¥:")
        print("  1. process_attrdir_emission í…Œì´ë¸”ì— cumulative_emission í•„ë“œ ì¶”ê°€")
        print("  2. ë°°ì¶œëŸ‰ ì „íŒŒ ì´ë ¥ í…Œì´ë¸” ìƒì„± (emission_propagation_log)")
        print("  3. ê³µì • ì²´ì¸ ìˆœì„œ ì •ë³´ í…Œì´ë¸” ìƒì„± (process_sequence)")
        
        # 7. ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
        print("\nğŸ’¾ 7. ë¶„ì„ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥")
        print("=" * 50)
        
        analysis_result = {
            'analysis_date': datetime.now().isoformat(),
            'database_url': DATABASE_URL.replace(DATABASE_URL.split('@')[0].split(':')[2], '***') if '@' in DATABASE_URL else '***',
            'tables': table_info,
            'recommendations': {
                'add_cumulative_emission': True,
                'create_propagation_log': True,
                'create_process_sequence': True
            }
        }
        
        with open('db_schema_analysis.json', 'w', encoding='utf-8') as f:
            json.dump(analysis_result, f, indent=2, ensure_ascii=False, default=str)
        
        print("âœ… ë¶„ì„ ê²°ê³¼ê°€ db_schema_analysis.json íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        await conn.close()
        print("\nğŸ”— DB ì—°ê²° ì¢…ë£Œ")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    print("ğŸš€ Railway DB ìŠ¤í‚¤ë§ˆ ë¶„ì„ ì‹œì‘")
    print("=" * 50)
    
    asyncio.run(analyze_database_schema())
    
    print("\nğŸ¯ ë¶„ì„ ì™„ë£Œ! ë‹¤ìŒ ë‹¨ê³„:")
    print("1. db_schema_analysis.json íŒŒì¼ í™•ì¸")
    print("2. ìŠ¤í‚¤ë§ˆ í™•ì¥ ê³„íš ê²€í† ")
    print("3. DB ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±")
