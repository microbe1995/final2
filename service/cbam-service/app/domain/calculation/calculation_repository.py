# ============================================================================
# ğŸ§® Calculation Repository - CBAM ê³„ì‚° ë°ì´í„° ì ‘ê·¼
# ============================================================================

import logging
import asyncio
from typing import List, Dict, Any, Optional
from datetime import datetime
import asyncpg
import os
from sqlalchemy import select, text
from sqlalchemy.ext.asyncio import AsyncSession

logger = logging.getLogger(__name__)

class CalculationRepository:
    """CBAM ê³„ì‚° ë°ì´í„° ì ‘ê·¼ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.database_url = os.getenv('DATABASE_URL')
        if not self.database_url:
            logger.warning("DATABASE_URL í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë°ì´í„°ë² ì´ìŠ¤ ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.")
            # ë°ì´í„°ë² ì´ìŠ¤ URLì´ ì—†ì–´ë„ ì„œë¹„ìŠ¤ëŠ” ê³„ì† ì‹¤í–‰
            return
        
        # asyncpg ì—°ê²° í’€ ì´ˆê¸°í™”
        self.pool = None
        self._initialization_attempted = False
        # ì´ˆê¸°í™”ëŠ” ì„œë¹„ìŠ¤ ì‹œì‘ ì‹œ ë³„ë„ë¡œ í˜¸ì¶œí•´ì•¼ í•¨
    
    async def initialize(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ì´ˆê¸°í™”"""
        if self._initialization_attempted:
            return  # ì´ë¯¸ ì´ˆê¸°í™” ì‹œë„í–ˆìœ¼ë©´ ë‹¤ì‹œ ì‹œë„í•˜ì§€ ì•ŠìŒ
            
        if not self.database_url:
            logger.warning("DATABASE_URLì´ ì—†ì–´ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            self._initialization_attempted = True
            return
        
        self._initialization_attempted = True
        
        try:
            # asyncpg ì—°ê²° í’€ ìƒì„±
            self.pool = await asyncpg.create_pool(
                self.database_url,
                min_size=1,  # ìµœì†Œ ì—°ê²° ìˆ˜ë¥¼ ì¤„ì„
                max_size=10,  # ìµœëŒ€ ì—°ê²° ìˆ˜ë¥¼ ì¤„ì„
                command_timeout=30,  # íƒ€ì„ì•„ì›ƒì„ ì¤„ì„
                server_settings={
                    'application_name': 'cbam-service'
                }
            )
            
            logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ìƒì„± ì„±ê³µ")
            
            # í…Œì´ë¸” ë° íŠ¸ë¦¬ê±° ìƒì„±ì€ ì„ íƒì ìœ¼ë¡œ ì‹¤í–‰
            try:
                await self._create_tables_async()
                await self._create_triggers_async()
            except Exception as e:
                logger.warning(f"âš ï¸ í…Œì´ë¸”/íŠ¸ë¦¬ê±° ìƒì„± ì‹¤íŒ¨ (ê¸°ë³¸ ê¸°ëŠ¥ì€ ì •ìƒ): {e}")
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {str(e)}")
            # ì—°ê²° ì‹¤íŒ¨í•´ë„ ì„œë¹„ìŠ¤ëŠ” ê³„ì† ì‹¤í–‰
            logger.warning("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨ë¡œ ì¸í•´ ì¼ë¶€ ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.")
            self.pool = None
    
    async def _ensure_pool_initialized(self):
        """ì—°ê²° í’€ì´ ì´ˆê¸°í™”ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³ , í•„ìš”ì‹œ ì´ˆê¸°í™”"""
        if not self.pool and not self._initialization_attempted:
            await self.initialize()
        
        if not self.pool:
            raise Exception("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    

    async def _create_tables_async(self):
        """í…Œì´ë¸” ìƒì„± (ë¹„ë™ê¸°)"""
        if not self.pool:
            logger.warning("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
            
        try:
            async with self.pool.acquire() as conn:
                # 1. install í…Œì´ë¸” ìƒì„±
                result = await conn.fetchval("""
                    SELECT EXISTS (
                        SELECT FROM information_schema.tables 
                        WHERE table_name = 'install'
                    );
                """)
                
                if not result:
                    logger.info("âš ï¸ install í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
                    
                    await conn.execute("""
                        CREATE TABLE install (
                            id SERIAL PRIMARY KEY,
                            install_name TEXT NOT NULL,
                            reporting_year INTEGER NOT NULL DEFAULT EXTRACT(YEAR FROM NOW()),
                            created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                            updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
                        );
                    """)
                    
                    logger.info("âœ… install í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
                else:
                    logger.info("âœ… install í…Œì´ë¸” í™•ì¸ ì™„ë£Œ")
                
                # 2. product í…Œì´ë¸” ìƒì„±
                result = await conn.fetchval("""
                    SELECT EXISTS (
                        SELECT FROM information_schema.tables 
                        WHERE table_name = 'product'
                    );
                """)
                
                if not result:
                    logger.info("âš ï¸ product í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
                    
                    await conn.execute("""
                        CREATE TABLE product (
                            id SERIAL PRIMARY KEY,
                            install_id INTEGER NOT NULL REFERENCES install(id) ON DELETE CASCADE,
                            product_name TEXT NOT NULL,
                            product_category TEXT NOT NULL,
                            prostart_period DATE NOT NULL,
                            proend_period DATE NOT NULL,
                            product_amount NUMERIC(15, 6) NOT NULL DEFAULT 0,
                            cncode_total TEXT,
                            goods_name TEXT,
                            goods_engname TEXT,
                            aggrgoods_name TEXT,
                            aggrgoods_engname TEXT,
                            product_sell NUMERIC(15, 6) DEFAULT 0,
                            product_eusell NUMERIC(15, 6) DEFAULT 0,
                            created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                            updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
                        );
                    """)
                    
                    logger.info("âœ… product í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
                else:
                    logger.info("âœ… product í…Œì´ë¸” í™•ì¸ ì™„ë£Œ")
                
                # 3. process í…Œì´ë¸” ìƒì„±
                result = await conn.fetchval("""
                    SELECT EXISTS (
                        SELECT FROM information_schema.tables 
                        WHERE table_name = 'process'
                    );
                """)
                
                if not result:
                    logger.info("âš ï¸ process í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
                    
                    await conn.execute("""
                        CREATE TABLE process (
                            id SERIAL PRIMARY KEY,
                            process_name TEXT NOT NULL,
                            start_period DATE NOT NULL,
                            end_period DATE NOT NULL,
                            created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                            updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
                        );
                    """)
                    
                    logger.info("âœ… process í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
                else:
                    logger.info("âœ… process í…Œì´ë¸” í™•ì¸ ì™„ë£Œ")
                
                # 4. product_process ì¤‘ê°„ í…Œì´ë¸” ìƒì„±
                result = await conn.fetchval("""
                    SELECT EXISTS (
                        SELECT FROM information_schema.tables 
                        WHERE table_name = 'product_process'
                    );
                """)
                
                if not result:
                    logger.info("âš ï¸ product_process í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
                    
                    await conn.execute("""
                        CREATE TABLE product_process (
                            id SERIAL PRIMARY KEY,
                            product_id INTEGER NOT NULL REFERENCES product(id) ON DELETE CASCADE,
                            process_id INTEGER NOT NULL REFERENCES process(id) ON DELETE CASCADE,
                            created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                            updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                            UNIQUE(product_id, process_id)
                        );
                    """)
                    
                    logger.info("âœ… product_process í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
                else:
                    logger.info("âœ… product_process í…Œì´ë¸” í™•ì¸ ì™„ë£Œ")
                
                # 5. edge í…Œì´ë¸” ìƒì„±
                result = await conn.fetchval("""
                    SELECT EXISTS (
                        SELECT FROM information_schema.tables 
                        WHERE table_name = 'edge'
                    );
                """)
                
                if not result:
                    logger.info("âš ï¸ edge í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
                    
                    await conn.execute("""
                        CREATE TABLE edge (
                            id SERIAL PRIMARY KEY,
                            source_id INTEGER NOT NULL,
                            target_id INTEGER NOT NULL,
                            edge_kind TEXT NOT NULL,
                            created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                            updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
                        );
                    """)
                    
                    logger.info("âœ… edge í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
                else:
                    logger.info("âœ… edge í…Œì´ë¸” í™•ì¸ ì™„ë£Œ")
                
                # 6. process_attrdir_emission í…Œì´ë¸” ìƒì„±
                result = await conn.fetchval("""
                    SELECT EXISTS (
                        SELECT FROM information_schema.tables 
                        WHERE table_name = 'process_attrdir_emission'
                    );
                """)
                
                if not result:
                    logger.info("âš ï¸ process_attrdir_emission í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
                    
                    await conn.execute("""
                        CREATE TABLE process_attrdir_emission (
                            id SERIAL PRIMARY KEY,
                            process_id INTEGER NOT NULL REFERENCES process(id) ON DELETE CASCADE,
                            total_matdir_emission NUMERIC(15, 6) DEFAULT 0,
                            total_fueldir_emission NUMERIC(15, 6) DEFAULT 0,
                            attrdir_em NUMERIC(15, 6) DEFAULT 0,
                            calculation_date TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                            created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                            updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                            UNIQUE(process_id)
                        );
                    """)
                    
                    logger.info("âœ… process_attrdir_emission í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
                else:
                    logger.info("âœ… process_attrdir_emission í…Œì´ë¸” í™•ì¸ ì™„ë£Œ")
                
                logger.info("âœ… ëª¨ë“  ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” í™•ì¸/ìƒì„± ì™„ë£Œ")
                
        except Exception as e:
            logger.error(f"âŒ í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {str(e)}")
            logger.warning("âš ï¸ í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨ë¡œ ì¸í•´ ì¼ë¶€ ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    async def _create_triggers_async(self):
        """íŠ¸ë¦¬ê±° ìƒì„± (ë¹„ë™ê¸°)"""
        if not self.pool:
            logger.warning("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
            
        try:
            async with self.pool.acquire() as conn:
                # ê¸°ë³¸ì ì¸ íŠ¸ë¦¬ê±°ë§Œ ìƒì„± (í•„ìš”ì‹œ í™•ì¥)
                logger.info("âœ… íŠ¸ë¦¬ê±° ìƒì„± ì™„ë£Œ")
                
        except Exception as e:
            logger.error(f"âŒ íŠ¸ë¦¬ê±° ìƒì„± ì‹¤íŒ¨: {str(e)}")
            logger.warning("âš ï¸ íŠ¸ë¦¬ê±° ìƒì„± ì‹¤íŒ¨ë¡œ ì¸í•´ ì¼ë¶€ ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    async def get_processes_by_product(self, product_id: int) -> List[Dict[str, Any]]:
        """ì œí’ˆë³„ í”„ë¡œì„¸ìŠ¤ ëª©ë¡ ì¡°íšŒ"""
        await self._ensure_pool_initialized()
        
        try:
            async with self.pool.acquire() as conn:
                results = await conn.fetch("""
                    SELECT p.id, p.process_name, p.start_period, p.end_period, p.created_at, p.updated_at
                    FROM process p
                    JOIN product_process pp ON p.id = pp.process_id
                    WHERE pp.product_id = $1
                    ORDER BY p.id
                """, product_id)
                
                processes = []
                for row in results:
                    process_dict = dict(row)
                    # datetime.date ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                    if 'start_period' in process_dict and process_dict['start_period']:
                        process_dict['start_period'] = process_dict['start_period'].isoformat()
                    if 'end_period' in process_dict and process_dict['end_period']:
                        process_dict['end_period'] = process_dict['end_period'].isoformat()
                    processes.append(process_dict)
                
                return processes
                
        except Exception as e:
            logger.error(f"âŒ ì œí’ˆë³„ í”„ë¡œì„¸ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            raise e

    # ============================================================================
    # ğŸ”— ProductProcess ê´€ë ¨ ë©”ì„œë“œ (ë‹¤ëŒ€ë‹¤ ê´€ê³„)
    # ============================================================================
    
    async def create_product_process(self, product_process_data: Dict[str, Any]) -> Dict[str, Any]:
        """ì œí’ˆ-ê³µì • ê´€ê³„ ìƒì„±"""
        await self._ensure_pool_initialized()
        try:
            return await self._create_product_process_db(product_process_data)
        except Exception as e:
            logger.error(f"âŒ ì œí’ˆ-ê³µì • ê´€ê³„ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise
    
    async def delete_product_process(self, product_id: int, process_id: int) -> bool:
        """ì œí’ˆ-ê³µì • ê´€ê³„ ì‚­ì œ"""
        await self._ensure_pool_initialized()
        try:
            return await self._delete_product_process_db(product_id, process_id)
        except Exception as e:
            logger.error(f"âŒ ì œí’ˆ-ê³µì • ê´€ê³„ ì‚­ì œ ì‹¤íŒ¨: {str(e)}")
            raise

    # Edge ê´€ë ¨ Repository ë©”ì„œë“œë“¤ì€ edge ë„ë©”ì¸ìœ¼ë¡œ ë¶„ë¦¬ë¨

    # ============================================================================
    # ğŸ”— í†µí•© ê³µì • ê·¸ë£¹ ê´€ë ¨ Repository ë©”ì„œë“œ
    # ============================================================================

    async def get_process_chains_by_process_ids(self, process_ids: List[int]) -> List[Dict]:
        """ê³µì • IDë“¤ë¡œ í†µí•© ê·¸ë£¹ ì¡°íšŒ"""
        await self._ensure_pool_initialized()
            
        try:
            async with self.pool.acquire() as conn:
                # process_chain_link í…Œì´ë¸”ì„ í†µí•´ ê³µì •ì´ í¬í•¨ëœ ê·¸ë£¹ë“¤ ì¡°íšŒ
                chains = await conn.fetch("""
                    SELECT DISTINCT 
                        pc.id,
                        pc.chain_name,
                        pc.start_process_id,
                        pc.end_process_id,
                        pc.chain_length,
                        pc.is_active,
                        pc.created_at,
                        pc.updated_at
                    FROM process_chain pc
                    INNER JOIN process_chain_link pcl ON pc.id = pcl.chain_id
                    WHERE pcl.process_id = ANY($1)
                    ORDER BY pc.id
                """, process_ids)
                
                # ê° ê·¸ë£¹ì— í¬í•¨ëœ ê³µì • ëª©ë¡ë„ í•¨ê»˜ ì¡°íšŒ
                chain_list = []
                for chain in chains:
                    chain_dict = dict(chain)
                    chain_dict['processes'] = []
                    
                    # í•´ë‹¹ ê·¸ë£¹ì— í¬í•¨ëœ ê³µì • ëª©ë¡ ì¡°íšŒ
                    process_links = await conn.fetch("""
                        SELECT process_id, sequence_order
                        FROM process_chain_link
                        WHERE chain_id = $1
                        ORDER BY sequence_order
                    """, chain_dict['id'])
                    
                    chain_dict['processes'] = [link['process_id'] for link in process_links]
                    chain_list.append(chain_dict)
                
                return chain_list
        except Exception as e:
            logger.error(f"âŒ ê³µì • IDë¡œ í†µí•© ê·¸ë£¹ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            raise e

    # ============================================================================
    # ğŸ”— ProductProcess ê´€ë ¨ Repository ë©”ì„œë“œ
    # ============================================================================

    async def create_process_chain(self, chain_data: Dict) -> Dict:
        """í†µí•© ê³µì • ê·¸ë£¹ ìƒì„±"""
        await self._ensure_pool_initialized()
            
        try:
            async with self.pool.acquire() as conn:
                # process_chain í…Œì´ë¸”ì— ê·¸ë£¹ ì •ë³´ ì €ì¥
                chain = await conn.fetchrow("""
                    INSERT INTO process_chain 
                    (chain_name, start_process_id, end_process_id, chain_length, is_active, created_at, updated_at)
                    VALUES ($1, $2, $3, $4, $5, $6, $7)
                    RETURNING *
                """, (
                    chain_data['chain_name'],
                    chain_data['start_process_id'],
                    chain_data['end_process_id'],
                    chain_data['chain_length'],
                    chain_data['is_active'],
                    datetime.now(),
                    datetime.now()
                ))
                
                return dict(chain)
        except Exception as e:
            logger.error(f"âŒ í†µí•© ê³µì • ê·¸ë£¹ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise

    async def create_process_chain_link(self, link_data: Dict):
        """í†µí•© ê·¸ë£¹ì— ê³µì • ì—°ê²°"""
        await self._ensure_pool_initialized()
            
        try:
            async with self.pool.acquire() as conn:
                await conn.execute("""
                    INSERT INTO process_chain_link 
                    (chain_id, process_id, sequence_order, is_continue_edge, created_at, updated_at)
                    VALUES ($1, $2, $3, $4, $5, $6)
                """, (
                    link_data['chain_id'],
                    link_data['process_id'],
                    link_data['sequence_order'],
                    link_data['is_continue_edge'],
                    datetime.now(),
                    datetime.now()
                ))
                
        except Exception as e:
            logger.error(f"âŒ ê³µì • ê·¸ë£¹ ì—°ê²° ìƒì„± ì‹¤íŒ¨: {e}")
            raise e

    async def add_processes_to_chain(self, chain_id: int, process_ids: List[int]):
        """ê¸°ì¡´ ê·¸ë£¹ì— ìƒˆë¡œìš´ ê³µì •ë“¤ ì¶”ê°€"""
        await self._ensure_pool_initialized()
            
        try:
            async with self.pool.acquire() as conn:
                # í˜„ì¬ ê·¸ë£¹ì˜ ìµœëŒ€ ìˆœì„œ ë²ˆí˜¸ ì¡°íšŒ
                result = await conn.fetchrow("""
                    SELECT COALESCE(MAX(sequence_order), 0) as max_order
                    FROM process_chain_link
                    WHERE chain_id = $1
                """, chain_id)
                
                max_order = result['max_order'] if result else 0
                
                # ìƒˆë¡œìš´ ê³µì •ë“¤ì„ ìˆœì„œëŒ€ë¡œ ì¶”ê°€
                for i, process_id in enumerate(process_ids, max_order + 1):
                    link_data = {
                        'chain_id': chain_id,
                        'process_id': process_id,
                        'sequence_order': i,
                        'is_continue_edge': True
                    }
                    await self.create_process_chain_link(link_data)
                
                # ê·¸ë£¹ ê¸¸ì´ ì—…ë°ì´íŠ¸
                await self.update_chain_length(chain_id)
                
        except Exception as e:
            logger.error(f"âŒ ê·¸ë£¹ì— ê³µì • ì¶”ê°€ ì‹¤íŒ¨: {e}")
            raise e

    async def update_chain_length(self, chain_id: int):
        """ê·¸ë£¹ ê¸¸ì´ ì—…ë°ì´íŠ¸"""
        await self._ensure_pool_initialized()
            
        try:
            async with self.pool.acquire() as conn:
                await conn.execute("""
                    UPDATE process_chain 
                    SET chain_length = (
                        SELECT COUNT(*) FROM process_chain_link WHERE chain_id = $1
                    ),
                    updated_at = $2
                    WHERE id = $3
                """, chain_id, datetime.now(), chain_id)
                
        except Exception as e:
            logger.error(f"âŒ ê·¸ë£¹ ê¸¸ì´ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            raise e

    async def update_process_chain_emission(self, chain_id: int, total_emission: float):
        """í†µí•© ê·¸ë£¹ì˜ ì´ ë°°ì¶œëŸ‰ ì—…ë°ì´íŠ¸"""
        try:
            # process_chain í…Œì´ë¸”ì— ì´ ë°°ì¶œëŸ‰ ì»¬ëŸ¼ì´ ìˆë‹¤ë©´ ì—…ë°ì´íŠ¸
            # (í˜„ì¬ëŠ” í…Œì´ë¸” êµ¬ì¡°ì— í•´ë‹¹ ì»¬ëŸ¼ì´ ì—†ì„ ìˆ˜ ìˆìŒ)
            logger.info(f"ğŸ”¥ í†µí•© ê·¸ë£¹ {chain_id} ì´ ë°°ì¶œëŸ‰ ì—…ë°ì´íŠ¸: {total_emission}")
            
        except Exception as e:
            logger.error(f"âŒ ê·¸ë£¹ ë°°ì¶œëŸ‰ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            raise e

    async def calculate_chain_integrated_emissions(self, chain_id: int) -> float:
        """í†µí•© ê·¸ë£¹ì˜ ì´ ë°°ì¶œëŸ‰ ê³„ì‚°"""
        await self._ensure_pool_initialized()
            
        try:
            async with self.pool.acquire() as conn:
                # ê·¸ë£¹ ë‚´ ëª¨ë“  ê³µì •ì˜ ë°°ì¶œëŸ‰ í•©ê³„ ê³„ì‚°
                result = await conn.fetchrow("""
                    SELECT COALESCE(SUM(attrdir_em), 0) as total_emission
                    FROM process_attrdir_emission pae
                    INNER JOIN process_chain_link pcl ON pae.process_id = pcl.process_id
                    WHERE pcl.chain_id = $1
                """, chain_id)
                
                total_emission = result['total_emission'] if result else 0
                
                return float(total_emission)
        except Exception as e:
            logger.error(f"âŒ í†µí•© ê·¸ë£¹ ë°°ì¶œëŸ‰ ê³„ì‚° ì‹¤íŒ¨: {str(e)}")
            raise e



    # ============================================================================
    # ğŸ“Š ë°°ì¶œëŸ‰ ê³„ì‚° ê´€ë ¨ Repository ë©”ì„œë“œ
    # ============================================================================

    async def calculate_process_attrdir_emission(self, process_id: int) -> Dict[str, Any]:
        """ê³µì •ë³„ ì§ì ‘ê·€ì†ë°°ì¶œëŸ‰ ê³„ì‚° ë° ì €ì¥"""
        await self._ensure_pool_initialized()
            
        try:
            async with self.pool.acquire() as conn:
                # 1. ê³µì • ì •ë³´ ì¡°íšŒ
                process_result = await conn.fetchrow("""
                    SELECT id, process_name FROM process WHERE id = $1
                """, process_id)
                
                if not process_result:
                    raise Exception(f"ê³µì • ID {process_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
                # 2. ì›ë£Œë³„ ì§ì ‘ë°°ì¶œëŸ‰ ê³„ì‚° (matdir í…Œì´ë¸” ê¸°ë°˜)
                matdir_emission = await conn.fetchrow("""
                    SELECT COALESCE(SUM(matdir_em), 0) as total_matdir_emission
                    FROM matdir
                    WHERE process_id = $1
                """, process_id)
                
                # 3. ì—°ë£Œë³„ ì§ì ‘ë°°ì¶œëŸ‰ ê³„ì‚° (fueldir í…Œì´ë¸” ê¸°ë°˜)
                fueldir_emission = await conn.fetchrow("""
                    SELECT COALESCE(SUM(fueldir_em), 0) as total_fueldir_emission
                    FROM fueldir
                    WHERE process_id = $1
                """, process_id)
                
                # 4. ì´ ì§ì ‘ê·€ì†ë°°ì¶œëŸ‰ ê³„ì‚°
                total_matdir = float(matdir_emission['total_matdir_emission']) if matdir_emission else 0.0
                total_fueldir = float(fueldir_emission['total_fueldir_emission']) if fueldir_emission else 0.0
                attrdir_em = total_matdir + total_fueldir
                
                # 5. ê²°ê³¼ë¥¼ process_attrdir_emission í…Œì´ë¸”ì— ì €ì¥/ì—…ë°ì´íŠ¸
                result = await conn.fetchrow("""
                    INSERT INTO process_attrdir_emission 
                    (process_id, total_matdir_emission, total_fueldir_emission, attrdir_em, calculation_date)
                    VALUES ($1, $2, $3, $4, NOW())
                    ON CONFLICT (process_id) 
                    DO UPDATE SET
                        total_matdir_emission = EXCLUDED.total_matdir_emission,
                        total_fueldir_emission = EXCLUDED.total_fueldir_emission,
                        attrdir_em = EXCLUDED.attrdir_em,
                        calculation_date = NOW(),
                        updated_at = NOW()
                    RETURNING *
                """, process_id, total_matdir, total_fueldir, attrdir_em)
                
                return dict(result)
                
        except Exception as e:
            logger.error(f"âŒ ê³µì •ë³„ ì§ì ‘ê·€ì†ë°°ì¶œëŸ‰ ê³„ì‚° ì‹¤íŒ¨: {str(e)}")
            raise e

    async def get_process_attrdir_emission(self, process_id: int) -> Optional[Dict[str, Any]]:
        """ê³µì •ë³„ ì§ì ‘ê·€ì†ë°°ì¶œëŸ‰ ì¡°íšŒ"""
        await self._ensure_pool_initialized()
            
        try:
            async with self.pool.acquire() as conn:
                result = await conn.fetchrow("""
                    SELECT * FROM process_attrdir_emission WHERE process_id = $1
                """, process_id)
                
                return dict(result) if result else None
                
        except Exception as e:
            logger.error(f"âŒ ê³µì •ë³„ ì§ì ‘ê·€ì†ë°°ì¶œëŸ‰ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            raise e

    async def get_all_process_attrdir_emissions(self) -> List[Dict[str, Any]]:
        """ëª¨ë“  ê³µì •ë³„ ì§ì ‘ê·€ì†ë°°ì¶œëŸ‰ ì¡°íšŒ"""
        await self._ensure_pool_initialized()
            
        try:
            async with self.pool.acquire() as conn:
                results = await conn.fetch("""
                    SELECT * FROM process_attrdir_emission ORDER BY process_id
                """)
                
                return [dict(row) for row in results]
                
        except Exception as e:
            logger.error(f"âŒ ëª¨ë“  ê³µì •ë³„ ì§ì ‘ê·€ì†ë°°ì¶œëŸ‰ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            raise e

    async def calculate_product_total_emission(self, product_id: int) -> Dict[str, Any]:
        """ì œí’ˆë³„ ì´ ë°°ì¶œëŸ‰ ê³„ì‚°"""
        await self._ensure_pool_initialized()
            
        try:
            async with self.pool.acquire() as conn:
                # 1. ì œí’ˆ ì •ë³´ ì¡°íšŒ
                product_result = await conn.fetchrow("""
                    SELECT id, product_name FROM product WHERE id = $1
                """, product_id)
                
                if not product_result:
                    raise Exception(f"ì œí’ˆ ID {product_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
                # 2. ì œí’ˆê³¼ ì—°ê²°ëœ ê³µì •ë“¤ì˜ ë°°ì¶œëŸ‰ ì¡°íšŒ
                process_emissions = await conn.fetch("""
                    SELECT 
                        p.id as process_id,
                        p.process_name,
                        pae.total_matdir_emission,
                        pae.total_fueldir_emission,
                        pae.attrdir_em
                    FROM process p
                    JOIN product_process pp ON p.id = pp.process_id
                    LEFT JOIN process_attrdir_emission pae ON p.id = pae.process_id
                    WHERE pp.product_id = $1
                    ORDER BY p.id
                """, product_id)
                
                # 3. ì´ ë°°ì¶œëŸ‰ ê³„ì‚°
                total_emission = 0.0
                process_count = 0
                
                for pe in process_emissions:
                    if pe['attrdir_em']:
                        total_emission += float(pe['attrdir_em'])
                    process_count += 1
                
                return {
                    'product_id': product_id,
                    'product_name': product_result['product_name'],
                    'total_emission': total_emission,
                    'process_count': process_count,
                    'process_emissions': [dict(pe) for pe in process_emissions]
                }
                
        except Exception as e:
            logger.error(f"âŒ ì œí’ˆë³„ ì´ ë°°ì¶œëŸ‰ ê³„ì‚° ì‹¤íŒ¨: {str(e)}")
            raise e

    # ============================================================================
    # ğŸ”„ ê³µì • ê°„ ê°’ ì „íŒŒ ê´€ë ¨ Repository ë©”ì„œë“œë“¤
    # ============================================================================
    
    async def update_process_attrdir_emission(self, process_id: int, update_data: Dict[str, Any]) -> bool:
        """ê³µì •ë³„ ì§ì ‘ê·€ì†ë°°ì¶œëŸ‰ ì—…ë°ì´íŠ¸"""
        await self._ensure_pool_initialized()
            
        try:
            async with self.pool.acquire() as conn:
                # ì—…ë°ì´íŠ¸í•  í•„ë“œë“¤ë§Œ ì¶”ì¶œ
                set_clauses = []
                values = [process_id]
                param_count = 1
                
                for key, value in update_data.items():
                    if key in ['total_matdir_emission', 'total_fueldir_emission', 'attrdir_em']:
                        set_clauses.append(f"{key} = ${param_count + 1}")
                        values.append(value)
                        param_count += 1
                
                if not set_clauses:
                    logger.warning("ì—…ë°ì´íŠ¸í•  í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
                    return False
                
                # updated_at í•„ë“œ ì¶”ê°€
                set_clauses.append("updated_at = NOW()")
                
                query = f"""
                    UPDATE process_attrdir_emission 
                    SET {', '.join(set_clauses)}
                    WHERE process_id = $1
                """
                
                result = await conn.execute(query, *values)
                
                if result == "UPDATE 1":
                    logger.info(f"âœ… ê³µì • {process_id} ë°°ì¶œëŸ‰ ì—…ë°ì´íŠ¸ ì„±ê³µ")
                    return True
                else:
                    logger.warning(f"âš ï¸ ê³µì • {process_id} ë°°ì¶œëŸ‰ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {result}")
                    return False
                
        except Exception as e:
            logger.error(f"âŒ ê³µì •ë³„ ì§ì ‘ê·€ì†ë°°ì¶œëŸ‰ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
            raise e
    
    async def get_continue_edges(self) -> List[Dict[str, Any]]:
        """ëª¨ë“  continue ì—£ì§€ ì¡°íšŒ"""
        await self._ensure_pool_initialized()
            
        try:
            async with self.pool.acquire() as conn:
                results = await conn.fetch("""
                    SELECT 
                        e.id,
                        e.source_id,
                        e.target_id,
                        e.source_node_type,
                        e.target_node_type,
                        e.edge_kind
                    FROM edge e
                    WHERE e.edge_kind = 'continue'
                    AND e.source_node_type = 'process'
                    AND e.target_node_type = 'process'
                    ORDER BY e.id
                """)
                
                return [dict(row) for row in results]
                
        except Exception as e:
            logger.error(f"âŒ continue ì—£ì§€ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            raise e
    
    async def get_outgoing_continue_edges(self, process_id: int) -> List[Dict[str, Any]]:
        """íŠ¹ì • ê³µì •ì—ì„œ ë‚˜ê°€ëŠ” continue ì—£ì§€ë“¤ ì¡°íšŒ"""
        await self._ensure_pool_initialized()
            
        try:
            async with self.pool.acquire() as conn:
                results = await conn.fetch("""
                    SELECT 
                        e.id,
                        e.source_id,
                        e.target_id,
                        e.source_node_type,
                        e.target_node_type,
                        e.edge_kind
                    FROM edge e
                    WHERE e.edge_kind = 'continue'
                    AND e.source_node_type = 'process'
                    AND e.target_node_type = 'process'
                    AND e.source_id = $1
                    ORDER BY e.id
                """, process_id)
                
                return [dict(row) for row in results]
                
        except Exception as e:
            logger.error(f"âŒ ê³µì • {process_id}ì˜ ë‚˜ê°€ëŠ” continue ì—£ì§€ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            raise e
    
    async def get_isolated_processes(self) -> List[int]:
        """ê³ ë¦½ëœ ê³µì •ë“¤ ì¡°íšŒ (ì—£ì§€ê°€ ì—†ëŠ” ê³µì •)"""
        await self._ensure_pool_initialized()
            
        try:
            async with self.pool.acquire() as conn:
                results = await conn.fetch("""
                    SELECT p.id
                    FROM process p
                    LEFT JOIN edge e ON (
                        (e.source_node_type = 'process' AND e.source_id = p.id) OR
                        (e.target_node_type = 'process' AND e.target_id = p.id)
                    )
                    WHERE e.id IS NULL
                    ORDER BY p.id
                """)
                
                return [row['id'] for row in results]
                
        except Exception as e:
            logger.error(f"âŒ ê³ ë¦½ëœ ê³µì • ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            raise e
    
    async def get_very_long_chains(self, max_length: int = 20) -> List[Dict[str, Any]]:
        """ë§¤ìš° ê¸´ ì²´ì¸ë“¤ ì¡°íšŒ (ë¬´í•œ ë£¨í”„ ê°€ëŠ¥ì„± í™•ì¸)"""
        await self._ensure_pool_initialized()
            
        try:
            async with self.pool.acquire() as conn:
                # ì¬ê·€ CTEë¥¼ ì‚¬ìš©í•˜ì—¬ ì²´ì¸ ê¸¸ì´ ê³„ì‚°
                results = await conn.fetch(f"""
                    WITH RECURSIVE process_chain AS (
                        -- ì‹œì‘ì : ë“¤ì–´ì˜¤ëŠ” ì—£ì§€ê°€ ì—†ëŠ” ê³µì •ë“¤
                        SELECT 
                            p.id as process_id,
                            p.process_name,
                            1 as chain_length,
                            ARRAY[p.id] as path
                        FROM process p
                        LEFT JOIN edge e ON e.target_node_type = 'process' AND e.target_id = p.id
                        WHERE e.id IS NULL
                        
                        UNION ALL
                        
                        -- ì¬ê·€: continue ì—£ì§€ë¥¼ ë”°ë¼ ë‹¤ìŒ ê³µì •ìœ¼ë¡œ
                        SELECT 
                            p.id,
                            p.process_name,
                            pc.chain_length + 1,
                            pc.path || p.id
                        FROM process p
                        JOIN edge e ON e.source_node_type = 'process' AND e.source_id = p.id
                        JOIN process_chain pc ON e.target_node_type = 'process' AND e.target_id = pc.process_id
                        WHERE e.edge_kind = 'continue'
                        AND pc.chain_length < {max_length}
                        AND p.id != ALL(pc.path)  -- ìˆœí™˜ ë°©ì§€
                    )
                    SELECT 
                        process_id,
                        process_name,
                        chain_length,
                        path
                    FROM process_chain
                    WHERE chain_length >= {max_length}
                    ORDER BY chain_length DESC, process_id
                """)
                
                return [dict(row) for row in results]
                
        except Exception as e:
            logger.error(f"âŒ ê¸´ ì²´ì¸ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            raise e
    
    async def get_process(self, process_id: int) -> Optional[Dict[str, Any]]:
        """ê³µì • ì •ë³´ ì¡°íšŒ"""
        await self._ensure_pool_initialized()
            
        try:
            async with self.pool.acquire() as conn:
                result = await conn.fetchrow("""
                    SELECT id, process_name FROM process WHERE id = $1
                """, process_id)
                
                return dict(result) if result else None
                
        except Exception as e:
            logger.error(f"âŒ ê³µì • ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            raise e













