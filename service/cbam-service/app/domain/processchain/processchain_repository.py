# ============================================================================
# ğŸ”„ ProcessChain Repository - í†µí•© ê³µì • ê·¸ë£¹ ë°ì´í„° ë ˆí¬ì§€í† ë¦¬
# ============================================================================

import logging
import asyncio
import os
from typing import List, Dict, Any, Optional
from datetime import datetime
from decimal import Decimal
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, text, func, create_engine
from sqlalchemy.orm import sessionmaker, Session

from .processchain_entity import (
    ProcessChain, ProcessChainLink, Base
)

logger = logging.getLogger(__name__)

class ProcessChainRepository:
    """í†µí•© ê³µì • ê·¸ë£¹ ë ˆí¬ì§€í† ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        """ë ˆí¬ì§€í† ë¦¬ ì´ˆê¸°í™”"""
        self.database_url = os.getenv("DATABASE_URL")
        if not self.database_url:
            raise ValueError("DATABASE_URL í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        self.engine = create_engine(self.database_url)
        self.SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=self.engine)
        
        # í…Œì´ë¸” ìƒì„±
        self._create_tables()
    
    def _create_tables(self):
        """í…Œì´ë¸” ìƒì„±"""
        try:
            Base.metadata.create_all(bind=self.engine)
            logger.info("âœ… processchain í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ í…Œì´ë¸” ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            raise e
    
    def get_db(self) -> Session:
        """ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ ë°˜í™˜"""
        return self.SessionLocal()
    
    # ============================================================================
    # ğŸ”„ ProcessChain ê´€ë ¨ ë©”ì„œë“œ (í†µí•© ê³µì • ê·¸ë£¹)
    # ============================================================================
    
    async def create_process_chain(self, chain_data: Dict[str, Any]) -> ProcessChain:
        """í†µí•© ê³µì • ê·¸ë£¹ ìƒì„±"""
        try:
            with self.get_db() as db:
                chain = ProcessChain(**chain_data)
                db.add(chain)
                db.commit()
                db.refresh(chain)
                logger.info(f"âœ… í†µí•© ê³µì • ê·¸ë£¹ ìƒì„± ì„±ê³µ: ID {chain.id}")
                return chain
        except Exception as e:
            logger.error(f"âŒ í†µí•© ê³µì • ê·¸ë£¹ ìƒì„± ì‹¤íŒ¨: {e}")
            raise e
    
    async def get_process_chain(self, chain_id: int) -> Optional[ProcessChain]:
        """í†µí•© ê³µì • ê·¸ë£¹ ì¡°íšŒ"""
        try:
            with self.get_db() as db:
                chain = db.query(ProcessChain).filter(ProcessChain.id == chain_id).first()
                return chain
        except Exception as e:
            logger.error(f"âŒ í†µí•© ê³µì • ê·¸ë£¹ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            raise e
    
    async def get_all_process_chains(self) -> List[ProcessChain]:
        """ëª¨ë“  í†µí•© ê³µì • ê·¸ë£¹ ì¡°íšŒ"""
        try:
            with self.get_db() as db:
                chains = db.query(ProcessChain).filter(ProcessChain.is_active == True).all()
                return chains
        except Exception as e:
            logger.error(f"âŒ í†µí•© ê³µì • ê·¸ë£¹ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            raise e
    
    async def update_process_chain(self, chain_id: int, update_data: Dict[str, Any]) -> Optional[ProcessChain]:
        """í†µí•© ê³µì • ê·¸ë£¹ ìˆ˜ì •"""
        try:
            with self.get_db() as db:
                chain = db.query(ProcessChain).filter(ProcessChain.id == chain_id).first()
                if not chain:
                    return None
                
                for key, value in update_data.items():
                    if hasattr(chain, key):
                        setattr(chain, key, value)
                
                chain.updated_at = datetime.utcnow()
                db.commit()
                db.refresh(chain)
                logger.info(f"âœ… í†µí•© ê³µì • ê·¸ë£¹ ìˆ˜ì • ì„±ê³µ: ID {chain_id}")
                return chain
        except Exception as e:
            logger.error(f"âŒ í†µí•© ê³µì • ê·¸ë£¹ ìˆ˜ì • ì‹¤íŒ¨: {e}")
            raise e
    
    async def delete_process_chain(self, chain_id: int) -> bool:
        """í†µí•© ê³µì • ê·¸ë£¹ ì‚­ì œ"""
        try:
            with self.get_db() as db:
                chain = db.query(ProcessChain).filter(ProcessChain.id == chain_id).first()
                if not chain:
                    return False
                
                db.delete(chain)
                db.commit()
                logger.info(f"âœ… í†µí•© ê³µì • ê·¸ë£¹ ì‚­ì œ ì„±ê³µ: ID {chain_id}")
                return True
        except Exception as e:
            logger.error(f"âŒ í†µí•© ê³µì • ê·¸ë£¹ ì‚­ì œ ì‹¤íŒ¨: {e}")
            raise e
    
    # ============================================================================
    # ğŸ”— ProcessChainLink ê´€ë ¨ ë©”ì„œë“œ (ê·¸ë£¹ ë‚´ ê³µì • ë©¤ë²„)
    # ============================================================================
    
    async def create_process_chain_link(self, link_data: Dict[str, Any]) -> ProcessChainLink:
        """í†µí•© ê³µì • ê·¸ë£¹ ë§í¬ ìƒì„±"""
        try:
            with self.get_db() as db:
                link = ProcessChainLink(**link_data)
                db.add(link)
                db.commit()
                db.refresh(link)
                logger.info(f"âœ… ê·¸ë£¹ ë§í¬ ìƒì„± ì„±ê³µ: ID {link.id}")
                return link
        except Exception as e:
            logger.error(f"âŒ ê·¸ë£¹ ë§í¬ ìƒì„± ì‹¤íŒ¨: {e}")
            raise e
    
    async def get_chain_links(self, chain_id: int) -> List[ProcessChainLink]:
        """ê·¸ë£¹ì— ì†í•œ ê³µì •ë“¤ ì¡°íšŒ"""
        try:
            with self.get_db() as db:
                links = db.query(ProcessChainLink).filter(
                    ProcessChainLink.chain_id == chain_id
                ).order_by(ProcessChainLink.sequence_order).all()
                return links
        except Exception as e:
            logger.error(f"âŒ ê·¸ë£¹ ë§í¬ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            raise e
    
    async def delete_chain_links(self, chain_id: int) -> bool:
        """ê·¸ë£¹ì˜ ëª¨ë“  ë§í¬ ì‚­ì œ"""
        try:
            with self.get_db() as db:
                db.query(ProcessChainLink).filter(
                    ProcessChainLink.chain_id == chain_id
                ).delete()
                db.commit()
                logger.info(f"âœ… ê·¸ë£¹ ë§í¬ ì‚­ì œ ì„±ê³µ: chain_id {chain_id}")
                return True
        except Exception as e:
            logger.error(f"âŒ ê·¸ë£¹ ë§í¬ ì‚­ì œ ì‹¤íŒ¨: {e}")
            raise e
    
    # ============================================================================
    # ğŸ” í†µí•© ê³µì • ê·¸ë£¹ ìë™ íƒì§€ ë©”ì„œë“œ
    # ============================================================================
    
    async def detect_process_chains(self, max_chain_length: int = 10) -> List[Dict[str, Any]]:
        """ì—°ê²°ëœ ê³µì •ë“¤ì„ í†µí•© ê³µì • ê·¸ë£¹ìœ¼ë¡œ ìë™ íƒì§€"""
        try:
            with self.get_db() as db:
                # Recursive CTEë¥¼ ì‚¬ìš©í•˜ì—¬ ì—°ê²°ëœ ê³µì • ì²´ì¸ íƒì§€
                query = text("""
                    WITH RECURSIVE process_paths AS (
                        -- ì‹œì‘ì : continue ì—£ì§€ê°€ ìˆëŠ” ê³µì •ë“¤
                        SELECT 
                            e.source_id as start_process,
                            e.target_id as current_process,
                            ARRAY[e.source_id, e.target_id] as path,
                            1 as depth
                        FROM edge e
                        WHERE e.edge_kind = 'continue'
                        
                        UNION ALL
                        
                        -- ì¬ê·€ì ìœ¼ë¡œ ì—°ê²°ëœ ê³µì •ë“¤ ì¶”ê°€
                        SELECT 
                            pp.start_process,
                            e.target_id,
                            pp.path || e.target_id,
                            pp.depth + 1
                        FROM process_paths pp
                        JOIN edge e ON e.source_id = pp.current_process
                        WHERE e.edge_kind = 'continue'
                        AND pp.depth < :max_depth
                        AND e.target_id != ALL(pp.path)  -- ìˆœí™˜ ë°©ì§€
                    )
                    SELECT 
                        start_process,
                        current_process,
                        path,
                        depth,
                        array_length(path, 1) as chain_length
                    FROM process_paths
                    WHERE depth >= 2  -- ìµœì†Œ 2ê°œ ê³µì •ì´ ì—°ê²°ëœ ê²½ìš°ë§Œ
                    ORDER BY start_process, depth DESC
                """)
                
                result = db.execute(query, {"max_depth": max_chain_length})
                chains = []
                
                for row in result:
                    chain_info = {
                        "start_process_id": row.start_process,
                        "end_process_id": row.current_process,
                        "chain_length": row.chain_length,
                        "process_path": row.path,
                        "depth": row.depth
                    }
                    chains.append(chain_info)
                
                logger.info(f"âœ… í†µí•© ê³µì • ê·¸ë£¹ íƒì§€ ì™„ë£Œ: {len(chains)}ê°œ ë°œê²¬")
                return chains
                
        except Exception as e:
            logger.error(f"âŒ í†µí•© ê³µì • ê·¸ë£¹ íƒì§€ ì‹¤íŒ¨: {e}")
            raise e
    
    # ============================================================================
    # ğŸ“Š í†µí•© ê³µì • ê·¸ë£¹ ë°°ì¶œëŸ‰ ê³„ì‚° ë©”ì„œë“œ
    # ============================================================================
    
    async def calculate_chain_integrated_emissions(self, chain_id: int) -> Dict[str, Any]:
        """í†µí•© ê³µì • ê·¸ë£¹ì˜ ì´ ë°°ì¶œëŸ‰ ê³„ì‚°"""
        try:
            with self.get_db() as db:
                # ê·¸ë£¹ì— ì†í•œ ê³µì •ë“¤ ì¡°íšŒ
                links = await self.get_chain_links(chain_id)
                process_ids = [link.process_id for link in links]
                
                if not process_ids:
                    return {
                        "chain_id": chain_id,
                        "integrated_matdir_emission": 0,
                        "integrated_fueldir_emission": 0,
                        "integrated_attrdir_em": 0,
                        "process_count": 0
                    }
                
                # ê° ê³µì •ì˜ ë°°ì¶œëŸ‰ ì¡°íšŒ
                query = text("""
                    SELECT 
                        process_id,
                        COALESCE(matdir_em, 0) as matdir_em,
                        COALESCE(fueldir_em, 0) as fueldir_em,
                        COALESCE(attrdir_em, 0) as attrdir_em
                    FROM process_attrdir_emission
                    WHERE process_id = ANY(:process_ids)
                """)
                
                result = db.execute(query, {"process_ids": process_ids})
                emissions = result.fetchall()
                
                # ê·¸ë£¹ì˜ ì´ ë°°ì¶œëŸ‰ ê³„ì‚° (SUM)
                total_matdir = sum(Decimal(str(row.matdir_em)) for row in emissions)
                total_fueldir = sum(Decimal(str(row.fueldir_em)) for row in emissions)
                total_attrdir = sum(Decimal(str(row.attrdir_em)) for row in emissions)
                
                integrated_emission = {
                    "chain_id": chain_id,
                    "integrated_matdir_emission": float(total_matdir),
                    "integrated_fueldir_emission": float(total_fueldir),
                    "integrated_attrdir_em": float(total_attrdir),
                    "process_count": len(process_ids),
                    "process_ids": process_ids
                }
                
                logger.info(f"âœ… í†µí•© ê³µì • ê·¸ë£¹ ë°°ì¶œëŸ‰ ê³„ì‚° ì™„ë£Œ: chain_id {chain_id}")
                return integrated_emission
                
        except Exception as e:
            logger.error(f"âŒ í†µí•© ê³µì • ê·¸ë£¹ ë°°ì¶œëŸ‰ ê³„ì‚° ì‹¤íŒ¨: {e}")
            raise e
    
    async def auto_detect_and_calculate_chains(self, max_chain_length: int = 10) -> Dict[str, Any]:
        """í†µí•© ê³µì • ê·¸ë£¹ ìë™ íƒì§€ ë° ë°°ì¶œëŸ‰ ê³„ì‚°"""
        try:
            # 1. ê¸°ì¡´ ê·¸ë£¹ë“¤ ë¹„í™œì„±í™”
            with self.get_db() as db:
                db.query(ProcessChain).update({"is_active": False})
                db.commit()
            
            # 2. ìƒˆë¡œìš´ ê·¸ë£¹ë“¤ íƒì§€
            detected_chains = await self.detect_process_chains(max_chain_length)
            
            created_chains = []
            total_integrated_emission = Decimal('0')
            
            for chain_info in detected_chains:
                # 3. ê·¸ë£¹ ìƒì„±
                chain_data = {
                    "chain_name": f"í†µí•©ê³µì •ê·¸ë£¹-{chain_info['start_process_id']}-{chain_info['end_process_id']}",
                    "start_process_id": chain_info["start_process_id"],
                    "end_process_id": chain_info["end_process_id"],
                    "chain_length": chain_info["chain_length"],
                    "is_active": True
                }
                
                chain = await self.create_process_chain(chain_data)
                
                # 4. ê·¸ë£¹ì— ê³µì •ë“¤ ì¶”ê°€
                for i, process_id in enumerate(chain_info["process_path"]):
                    link_data = {
                        "chain_id": chain.id,
                        "process_id": process_id,
                        "sequence_order": i + 1,
                        "is_continue_edge": True
                    }
                    await self.create_process_chain_link(link_data)
                
                # 5. ê·¸ë£¹ ë°°ì¶œëŸ‰ ê³„ì‚°
                emission_result = await self.calculate_chain_integrated_emissions(chain.id)
                total_integrated_emission += Decimal(str(emission_result["integrated_attrdir_em"]))
                
                created_chains.append({
                    "chain_id": chain.id,
                    "chain_name": chain.chain_name,
                    "process_count": emission_result["process_count"],
                    "integrated_emission": emission_result["integrated_attrdir_em"]
                })
            
            result = {
                "detected_chains": len(created_chains),
                "total_calculated_processes": sum(c["process_count"] for c in created_chains),
                "total_integrated_emission": float(total_integrated_emission),
                "created_chains": created_chains,
                "calculation_date": datetime.utcnow()
            }
            
            logger.info(f"âœ… í†µí•© ê³µì • ê·¸ë£¹ ìë™ íƒì§€ ë° ê³„ì‚° ì™„ë£Œ: {len(created_chains)}ê°œ ê·¸ë£¹")
            return result
            
        except Exception as e:
            logger.error(f"âŒ í†µí•© ê³µì • ê·¸ë£¹ ìë™ íƒì§€ ë° ê³„ì‚° ì‹¤íŒ¨: {e}")
            raise e
    
    # ============================================================================
    # ğŸ”„ SourceStream ê´€ë ¨ ë©”ì„œë“œ
    # ============================================================================
    
    async def create_source_stream(self, stream_data: Dict[str, Any]) -> SourceStream:
        """ì†ŒìŠ¤ ìŠ¤íŠ¸ë¦¼ ìƒì„±"""
        try:
            with self.get_db() as db:
                stream = SourceStream(**stream_data)
                db.add(stream)
                db.commit()
                db.refresh(stream)
                logger.info(f"âœ… ì†ŒìŠ¤ ìŠ¤íŠ¸ë¦¼ ìƒì„± ì„±ê³µ: ID {stream.id}")
                return stream
        except Exception as e:
            logger.error(f"âŒ ì†ŒìŠ¤ ìŠ¤íŠ¸ë¦¼ ìƒì„± ì‹¤íŒ¨: {e}")
            raise e
    
    async def get_source_streams(self, source_process_id: Optional[int] = None) -> List[SourceStream]:
        """ì†ŒìŠ¤ ìŠ¤íŠ¸ë¦¼ ì¡°íšŒ"""
        try:
            with self.get_db() as db:
                query = db.query(SourceStream)
                if source_process_id:
                    query = query.filter(SourceStream.source_process_id == source_process_id)
                streams = query.all()
                return streams
        except Exception as e:
            logger.error(f"âŒ ì†ŒìŠ¤ ìŠ¤íŠ¸ë¦¼ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            raise e
